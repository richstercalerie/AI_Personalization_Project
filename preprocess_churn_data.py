import pandas as pd

# âœ… File Paths
processed_data_path = "data/processed/preprocessed_churn_data.csv"
raw_data_path = "data/raw/customer_policy_data.csv"

# âœ… Load Data
df_raw = pd.read_csv(raw_data_path)
df_processed = pd.read_csv(processed_data_path)

# âœ… Ensure `customer_id` is an integer to prevent merge issues
df_raw["customer_id"] = df_raw["customer_id"].astype(int)
df_processed["customer_id"] = df_processed["customer_id"].astype(int)

# âœ… Keep only necessary columns from `df_raw`
df_raw = df_raw[['customer_id', 'policy_id', 'age', 'income', 'past_claims', 'engagement_score', 'occupation']]

# âœ… Drop duplicate columns from `df_processed` BEFORE merging
df_processed = df_processed.loc[:, ~df_processed.columns.duplicated()]

# âœ… Merge while keeping all customer IDs
df_processed = df_raw.merge(
    df_processed.drop(columns=['policy_id', 'age', 'income', 'past_claims', 'engagement_score', 'occupation'],
                      errors='ignore'),
    on="customer_id",
    how="outer"  # ðŸ”¥ Keeps all customers from both datasets
)

# âœ… Ensure 'churn' column exists with proper logic
if "churn" not in df_processed.columns:
    df_processed["churn"] = ((df_processed["past_claims"] > 2) | (df_processed["engagement_score"] < 50)).astype(int)

# âœ… Drop duplicate columns after merging (if any)
df_processed = df_processed.loc[:, ~df_processed.columns.duplicated()]

# âœ… One-Hot Encode `occupation` (Fix "Doctor" issue)
if "occupation" in df_processed.columns:
    df_processed = pd.get_dummies(df_processed, columns=["occupation"], dtype=int, drop_first=True)  # Avoids duplicate features

# âœ… Fill missing values
df_processed.fillna(0, inplace=True)

# âœ… Save the cleaned data
df_processed.to_csv(processed_data_path, index=False)

print(f"âœ… Data preprocessing complete! Saved as '{processed_data_path}'")
print("âœ… Data Columns After Processing:\n", df_processed.columns.tolist())  # Debugging line
print("âœ… Data Before Saving:\n", df_processed.tail(10))  # Print last 10 rows
